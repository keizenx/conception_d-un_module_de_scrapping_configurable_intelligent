# Backend - Module de Scraping Intelligent

Module de scraping configurable et intelligent capable d'analyser et d'extraire automatiquement des donnÃ©es structurÃ©es depuis n'importe quel type de page web.

## ğŸ¯ FonctionnalitÃ©s

- âœ… **DÃ©tection automatique** des collections d'items sur n'importe quelle page web
- âœ… **Extraction intelligente** de tous les champs pertinents (titre, prix, image, lien, description, date, auteur)
- âœ… **Support multi-types** : e-commerce, blog, actualitÃ©s, documentation, etc.
- âœ… **Mode hybride** : HTTP classique (rapide) ou Playwright (JavaScript)
- âœ… **Filtrage intelligent** : Exclut automatiquement navigation, pagination, menus
- âœ… **Scoring adaptatif** : Priorise les collections avec contenu riche

## ğŸ“ Structure du projet

```
backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ routes/
â”‚   â”‚       â”œâ”€â”€ analyze.py      # Endpoint d'analyse
â”‚   â”‚       â”œâ”€â”€ scrape.py       # Endpoint de scraping
â”‚   â”‚       â””â”€â”€ export.py       # Endpoint d'export
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ analyzer.py         # Algorithme de dÃ©tection
â”‚   â”‚   â”œâ”€â”€ scraper.py          # Extraction des donnÃ©es
â”‚   â”‚   â”œâ”€â”€ fetcher.py          # HTTP classique
â”‚   â”‚   â””â”€â”€ fetcher_playwright.py  # Support JavaScript
â”‚   â””â”€â”€ index.py                # Application FastAPI
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_manual.py          # Test interactif (recommandÃ©)
â”‚   â”œâ”€â”€ test_multi_types.py     # Validation multi-types
â”‚   â”œâ”€â”€ test_scraper.py         # Test e-commerce
â”‚   â”œâ”€â”€ test_playwright_ready.py # VÃ©rification Playwright
â”‚   â””â”€â”€ debug_*.py              # Scripts de debug
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ PROGRESS.md                 # Documentation de progression
â””â”€â”€ README.md                   # Ce fichier
```

## ğŸš€ Installation

### 1. CrÃ©er l'environnement virtuel (si pas dÃ©jÃ  fait)
```bash
cd ..
python -m venv venv
```

### 2. Activer l'environnement
```bash
# Windows
.\venv\Scripts\Activate.ps1

# Linux/Mac
source venv/bin/activate
```

### 3. Installer les dÃ©pendances
```bash
cd backend
pip install -r requirements.txt
```

### 4. (Optionnel) Installer Playwright pour le support JavaScript
```bash
pip install playwright==1.41.0
playwright install chromium
```

## ğŸ® Utilisation

### DÃ©marrer le serveur

```bash
cd backend
..\venv\Scripts\python.exe -m uvicorn src.index:app --reload --host 0.0.0.0 --port 8000
```

Le serveur sera accessible sur : **http://localhost:8000**

### Interface Swagger (recommandÃ© pour dÃ©buter)

Ouvrez votre navigateur : **http://localhost:8000/docs**

Vous aurez accÃ¨s Ã  une interface interactive pour tester les endpoints.

### Tester avec les scripts

```bash
cd tests

# Test manuel interactif (recommandÃ©)
..\venv\Scripts\python.exe test_manual.py

# Validation sur diffÃ©rents types de sites
..\venv\Scripts\python.exe test_multi_types.py

# Test e-commerce spÃ©cifique
..\venv\Scripts\python.exe test_scraper.py
```

Voir `tests/README.md` pour plus de dÃ©tails sur les tests.

## ğŸ“¡ API Endpoints

### POST /analyze
Analyse une URL et dÃ©tecte les collections d'items scrapables.

**ParamÃ¨tres :**
```json
{
  "url": "https://example.com",
  "max_candidates": 5,
  "max_items_preview": 5,
  "use_js": false
}
```

**RÃ©ponse :**
```json
{
  "success": true,
  "page_title": "Example Site",
  "summary": {
    "total_collections_found": 2,
    "detected_field_types": ["title", "price", "image", "link"]
  },
  "collections": [...]
}
```

### POST /scrape
Extrait tous les items d'une collection spÃ©cifique.

**ParamÃ¨tres :**
```json
{
  "url": "https://example.com",
  "collection_index": 0,
  "max_items": 1000,
  "use_js": false
}
```

**RÃ©ponse :**
```json
{
  "success": true,
  "summary": {
    "total_items_extracted": 20,
    "detected_field_types": ["title", "price", "image", "link"]
  },
  "items": [...]
}
```

## ğŸ¯ Exemples d'utilisation

### Exemple Python avec httpx

```python
import httpx

# 1. Analyser une page
response = httpx.post(
    "http://localhost:8000/analyze",
    json={"url": "https://books.toscrape.com/", "use_js": False}
)
data = response.json()
print(f"Collections trouvÃ©es: {data['summary']['total_collections_found']}")

# 2. Scraper la premiÃ¨re collection
response = httpx.post(
    "http://localhost:8000/scrape",
    json={"url": "https://books.toscrape.com/", "collection_index": 0}
)
data = response.json()
print(f"Items extraits: {data['summary']['total_items_extracted']}")
```

### Exemple curl

```bash
# Analyser
curl -X POST "http://localhost:8000/analyze" \
  -H "Content-Type: application/json" \
  -d '{"url": "https://books.toscrape.com/"}'

# Scraper
curl -X POST "http://localhost:8000/scrape" \
  -H "Content-Type: application/json" \
  -d '{"url": "https://books.toscrape.com/", "collection_index": 0}'
```

## ğŸ§ª Tests et validation

### Taux de rÃ©ussite actuel : **100% (7/7 sites)**

Sites validÃ©s :
- âœ… E-commerce : books.toscrape.com, scrapeme.live
- âœ… Blog : blog.python.org, realpython.com
- âœ… ActualitÃ©s : news.ycombinator.com, reddit.com
- âœ… Documentation : docs.python.org

Voir `PROGRESS.md` pour les dÃ©tails complets.

## ğŸ”§ Configuration

### Mode HTTP classique (par dÃ©faut)
- Plus rapide
- Fonctionne pour les sites HTML statiques
- `use_js: false`

### Mode Playwright (JavaScript)
- Plus lent mais plus complet
- NÃ©cessaire pour les sites avec contenu dynamique
- NÃ©cessite l'installation de Playwright
- `use_js: true`

## ğŸ“Š Performance

- **Analyse** : < 2 secondes (mode HTTP)
- **Scraping** : < 3 secondes pour 50 items (mode HTTP)
- **Mode Playwright** : +5-10 secondes (rendu JavaScript)

## ğŸ› DÃ©pannage

### Le serveur ne dÃ©marre pas
```bash
# VÃ©rifier que le port 8000 est libre
netstat -ano | findstr :8000

# Utiliser un autre port
uvicorn src.index:app --reload --port 8001
```

### Playwright ne fonctionne pas
```bash
# RÃ©installer Playwright
pip uninstall playwright
pip install playwright==1.41.0
playwright install chromium
```

### Aucune collection dÃ©tectÃ©e
- VÃ©rifiez que la page contient des Ã©lÃ©ments rÃ©pÃ©titifs (au moins 4)
- Essayez avec `use_js: true` si le contenu est chargÃ© en JavaScript
- Utilisez les scripts de debug dans `tests/` pour analyser la structure

## ğŸ“š Documentation

- `PROGRESS.md` : Progression dÃ©taillÃ©e et amÃ©liorations
- `tests/README.md` : Guide des tests
- Swagger UI : http://localhost:8000/docs

## ğŸ”® Prochaines Ã©tapes

- [ ] Support de la pagination automatique
- [ ] DÃ©tection et suivi des liens "Next"
- [ ] Export en diffÃ©rents formats (CSV, JSON, Excel)
- [ ] Cache et optimisation des requÃªtes

## ğŸ“ Licence

MIT
